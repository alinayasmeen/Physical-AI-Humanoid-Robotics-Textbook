---
sidebar_position: 2
---

# سہ ماہی جائزہ

یہ کیپسٹون سہ ماہی فزیکل اے آئی کا متعارف کراتا ہے—ایسے اے آئی سسٹمز جو حقیقت میں کام کرتے ہیں اور جسمانی قوانین کو سمجھتے ہیں۔ طلباء ہیومنوائڈ روبوٹس کو ڈیزائن، سیمیولیٹ، اور ڈپلائے کرنا سیکھتے ہیں جو کہ قدرتی انسانی بات چیت کر سکتے ہیں ROS 2، Gazebo، اور NVIDIA Isaac کا استعمال کرتے ہوئے۔ یہ ماڈل بیسڈ نقطہ نظر مربوط ہارڈویئر اور سافٹ ویئر اسٹیک کی مکمل سمجھ کو یقینی بناتا ہے جو جسمانی ذہانت کے لیے ضروری ہے۔

## ماڈل 1: روبوٹک نروسس سسٹم (ROS 2)

**مرکز:** روبوٹ کنٹرول کے لیے مڈل ویئر.
یہ ماڈل تمام روبوٹک سسٹمز کے لیے بنیادی مواصلاتی لیئر کو قائم کرتا ہے۔

* **ROS 2 نوڈز، ٹاپکس، اور سروسز:** طلباء گہرائی میں ROS 2 کے بنیادی تصورات میں جائیں گے۔ نوڈز انفرادی عمل ہیں جو کمپیوٹیشن انجام دیتے ہیں (جیسے ایک کیمرہ ڈرائیور نوڈ، ایک موٹر کنٹرول نوڈ). ٹاپکس نوڈز کو ڈیٹا کے تبادلے کے لیے ایک پبلش-سبسکرائب میکنزم فراہم کرتے ہیں (جیسے سینسر ریڈنگز، موٹر کمانڈز). سروسز متزامن درخواست-جواب کمیونیکیشن کو فعال کرتے ہیں، خاص کاموں کے لیے مناسب (جیسے روبوٹ کو کوئی چیز اٹھانے کی درخواست کرنا). ان کو سمجھنا طلباء کو پیچیدہ روبوٹ رویوں کو معمار بنانے کی اجازت دیتا ہے۔
* **`rclpy` کا استعمال کرتے ہوئے پائیتھن ایجنٹس کو ROS کنٹرولرز سے جوڑنا:** `rclpy` ROS 2 کے لیے پائیتھن کلائنٹ لائبریری ہے۔ یہ سیکشن اس پر توجہ مرکوز کرے گا کہ AI ایجنٹس جو پائیتھن میں تیار کیے گئے ہیں (جیسے مضبوط سیکھنا ایجنٹس، بیhevioral پلانرز) کس طرح ROS 2 کے ذریعے کم سطح کے روبوٹ ہارڈویئر کنٹرولرز اور سینسرز سے سیم سینس کر سکتے ہیں، جو بلند سطح کی ذہانت کو جسمانی ایکشنز میں چلانے کے قابل بناتا ہے۔
* **URDF (متحدہ روبوٹ کی تفصیل کا فارمیٹ) کو ہیومنوائڈز کے لیے سمجھنا:** URDF ایک XML فارمیٹ ہے جو روبوٹ کے تمام پہلوؤں کی وضاحت کے لیے استعمال ہوتا ہے، بشمول اس کی کنیمیٹک اور ڈائنا مک خصوصیات، وژوئل ظہور، اور کالیژن جیومیٹری۔ ہیومنوائڈز کے لیے، URDF میں جوائنٹس، لنکس، اور سینسر کے مقامات کی درست وضاحت سیمیولیشن کی درستی اور حقیقی دنیا کے کنٹرول کے لیے انتہائی ضروری ہے۔

## ماڈل 2: ڈیجیٹل ٹوئن (Gazebo & Unity)

**مرکز:** فزکس سیمیولیشن اور ماحول تعمیر کرنا.
روبوٹ اور ان کے ماحول کا حقیقت میں ڈیجیٹل ٹوئن تیار کرنا محفوظ اور کارآمد ترقی کے لیے انتہائی اہم ہے۔

* **Gazebo میں فزکس، گریویٹی، اور کالیژن سیمیولیٹ کرنا:** Gazebo ایک طاقتور 3D روبوٹ سیمیولیٹر ہے جو حقیقی دنیا کی فزکس کو درست طریقے سے ماڈل کرتا ہے۔ طلباء سیکھیں گے کہ سیمیولیشن کو کیسے ترتیب دیں اور چلائیں جہاں روبوٹ اپنے ماحول کے ساتھ بات چیت کریں، گریویٹی، فریکشن، اور کالیژن کا تجربہ کریں، جو مستحکم کنٹرول الگورتھم تیار کرنے کے لیے انتہائی ضروری ہے بغیر جسمانی ہارڈویئر کو نقصان پہنچائے۔
* **Unity میں ہائی فائیڈلٹی رینڈرنگ اور انسان-روبوٹ بات چیت:** جبکہ Gazebo فزکس میں ماہر ہے، Unity بہترین گریفکل رینڈرنگ کی صلاحیتوں کو فراہم کرتا ہے۔ یہ ماڈل یہ دیکھنے کے لیے ہے کہ Unity کو ویژوئلی میں مزید امیر سیمیولیشنز کے لیے کیسے استعمال کیا جا سکتا ہے، خاص طور پر انسان-روبوٹ بات چیت کے منظر ناموں کے لیے، جو حقیقی ویژوئل فیڈ بیک اور سمجھنے والے انٹرفیس ڈیزائن کی اجازت دیتا ہے۔
* **سینسرز کو سیمیولیٹ کرنا: LiDAR، ڈیپتھ کیمرے، اور IMUs:** روبوٹس کو سینسر ڈیٹا پر بہت انحصار ہوتا ہے۔ یہ سیکشن کورس کرتا ہے کہ کس طرح عام روبوٹ سینسرز—LiDAR (3D میپنگ اور رکاوٹ کا پتہ لگانے کے لیے)، ڈیپتھ کیمرے (اشیاء کے فاصلے اور شکل سمجھنے کے لیے)، اور IMUs (انرٹیل میزورمینٹ یونٹس، جہت اور ایکسلریشن کے لیے)—کو سیمیولیٹ کیا جائے تاکہ سینسر پرچیپشن الگورتھم کو تربیت دینے کے لیے مصنوعی ڈیٹا تیار کیا جا سکے۔

## ماڈل 3: اے آئی-روبوٹ دماغ (NVIDIA Isaac™)

**مرکز:** اعلیٰ پرچیپشن اور تربیت.
NVIDIA Isaac روبوٹکس کی ترقی کے لیے ایک جامع پلیٹ فارم فراہم کرتا ہے، خاص طور پر زیادہ کارکردگی والے کاموں کے لیے مناسب ہے۔

* **NVIDIA Isaac Sim: فوٹو ریلائزٹک سیمیولیشن اور مصنوعی ڈیٹا جنریشن:** Isaac Sim، NVIDIA Omniverse پر تعمیر شدہ، ایک انتہائی حقیقی، جسمانی طور پر درست 3D سیمیولیشن پلیٹ فارم فراہم کرتا ہے۔ یہ وسیع مقدار میں مختلف مصنوعی ڈیٹا تیار کرنے کے لیے استعمال ہوتا ہے، جو مضبوط ڈیپ لرننگ ماڈلز کو تربیت دینے کے لیے بے حد قیمتی ہے جن کے ماحول کو حقیقت میں نقل کرنا مشکل یا مہنگا ہو سکتا ہے۔
* **Isaac ROS: ہارڈویئر ایکسلریٹڈ VSLAM (ویژوئل SLAM) اور نیویگیشن:** Isaac ROS NVIDIA GPUs کو استعمال کرتے ہوئے ROS 2 پیکجز کے لیے ہارڈویئر ایکسلریٹڈ ROS 2 پیکجز فراہم کرتا ہے جو اہم روبوٹک فنکشنز کے لیے ہیں۔ اس میں **ویژوئل SLAM (سیمیولٹنیس لوکلائزیشن اینڈ میپنگ)** شامل ہے، جو روبوٹس کو ایک نامعلوم ماحول کا نقشہ تیار کرنے اور اسی وقت اس کے اندر اپنی جگہ کا تعین کرنے کے قابل بناتا ہے کیمرہ ڈیٹا کا استعمال کرتے ہوئے، اور جدید نیویگیشن کی صلاحیتوں کو۔
* **Nav2: بائی پیڈل ہیومنوائڈ موومنٹ کے لیے راستہ کی منصوبہ بندی:** Nav2 ROS 2 روبوٹس کے لیے ایک ماڈولر نیویگیشن فریم ورک ہے۔ یہ ماڈل Nav2 کے اصولوں کو ہیومنوائڈز کے منفرد چیلنجوں کے ساتھ ایڈاپٹ کرے گا، جو مستحکم راستہ کی منصوبہ بندی، رکاوٹوں سے بچاؤ، اور متحرک چلنے چلنے کے الگورتھم پر توجہ مرکوز کرے گا جو کہ جٹھل، انسان مرکزی ماحول کے لیے مناسب ہوں۔

## ماڈل 4: وژن-زبان-ایکشن (VLA)

**مرکز:** LLMs اور روبوٹکس کا اتحاد.
یہ ماڈل یہ دیکھتا ہے کہ کس طرح بڑے زبان کے ماڈلز (LLMs) روبوٹک انٹیلی جنس کو انسانی زبان کی سمجھ اور کوگنیٹو پلاننگ کے ذریعے جدید بنا رہے ہیں۔

* **وائس ٹو ایکشن: OpenAI Whisper کا استعمال آواز کمانڈز کے لیے:** طلباء سیکھیں گے کہ OpenAI Whisper کو کیسے انٹیگریٹ کرنا ہے، جو ایک جدید ترین آٹومیٹک سپیچ ریکگنیشن (ASR) سسٹم ہے، انسانی آواز کمانڈز کو متن میں تبدیل کرنے کے لیے۔ یہ متن پھر روبوٹ انٹیلی جنس کے لیے ان پٹ کے طور پر کام کرتا ہے، جو ہیومنوائڈ روبوٹس کے لیے مطابقت پذیر آواز کنٹرول کو فعال کرتا ہے۔
* **کوگنیٹو پلاننگ: LLMs کا استعمال قدرتی زبان ("کمرہ صاف کریں") کو ROS 2 ایکشنز کی ایک ترتیب میں تبدیل کرنے کے لیے:** یہ سیکشن AI اور روبوٹکس کے کٹنگ ایج پر ہے۔ طلباء یہ دیکھیں گے کہ LLMs کس طرح بلند سطح کے کوگنیٹو پلانر کے طور پر کام کر سکتے ہیں، جو مبہم قدرتی زبان کی ہدایات (جیسے "میرے لیے نیلا کپ لائیں") کو توڑ دیتے ہیں ایک سیریز میں عمل میں ROS 2 کمانڈز اور ذیلی کاموں میں جو روبوٹ انجام دے سکتا ہے۔ اس میں سیاق و سباق کو سمجھنا، اشیاء کی پہچان، اور ترتیب وار فیصلہ سازی شامل ہے۔
* **کیپسٹون پروجیکٹ: خود مختار ہیومنوائڈ:** یہ اختتامی پروجیکٹ تمام سیکھے گئے تصورات کو اکٹھا کرتا ہے۔ ایک سیمیولیٹڈ ہیومنوائڈ روبوٹ ایک آواز کمانڈ وصول کرے گا، جسے Whisper کے ذریعے پروسیس کیا جائے گا۔ ایک LLM-بیسڈ کوگنیٹو پلانر پھر اسے ایک سیریز میں نیویگیشن اور مینیپولیشن ٹاسکس میں تبدیل کرے گا۔ روبوٹ پھر Nav2 کا استعمال کرتے ہوئے ایک راستہ کی منصوبہ بندی کرے گا، اس کے سیمیولیٹڈ ماحول میں رکاوٹوں کے گرد نیویگیٹ کرے گا، کمپیوٹر وژن کی تکنیکوں (Isaac Sim ڈیٹا سے تربیت یافتہ) کا استعمال کرتے ہوئے ایک مخصوص چیز کی پہچان کرے گا، اور اسے اس کے روبوٹ ہاتھوں کا استعمال کرتے ہوئے چھوئے گا۔ یہ پروجیکٹ جسمانی AI کے لیے ایک مکمل ادراک-کوگنیشن-ایکشن لوپ کا مظاہرہ کرتا ہے۔
