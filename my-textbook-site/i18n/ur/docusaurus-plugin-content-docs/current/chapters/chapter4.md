---
sidebar_position: 5
---

# چیپٹر 4: ہیومنوائڈ روبوٹکس اور مصنوعی ذہانت میں اعلیٰ موضوعات

## 1. روبوٹ سیکھنے اور اسکل حاصل کرنا

### 1.1. روبوٹ سیکھنے کی بنیادیں

#### 1.1.1. روبوٹکس کے لیے مشین لرننگ کا تعارف

مشین لرننگ (ML) نے روبوٹکس میں ایک تبدیل کن نقطہ نظر کے طور پر ابھرا ہے، جس نے روبوٹس کو پیچیدہ رویے حاصل کرنے، غیر منظم ماحول میں مطابقت پذیر ہونے اور بڑھتی ہوئی خود مختاری کے ساتھ کاموں کو انجام دینے کے قابل بنایا ہے۔ روایتی طور پر پروگرام کردہ روبوٹس کے برعکس، جو صریح قاعدہ سیٹس پر انحصار کرتے ہیں، ML سے چلنے والے روبوٹس ڈیٹا، تجربہ، یا انسانی مظاہروں سے سیکھتے ہیں۔ یہ نقطہ نظر خاص طور پر اس وقت اہم ہے جب ہیومنوائڈ روبوٹس متحرک، انسانی مرکزی ماحول میں کام کر رہے ہوں، جہاں پیش پروگرام کردہ حل اکثر کمزور یا غیر عملی ہوتے ہیں۔ ایم ایل کا اTEGRیشن روبوٹس کو انسان نما ذہانت کے طریقے سے کام کرنے کے قابل بناتا ہے، ادراک کے ابہام، موٹر کنٹرول کی پیچیدگیوں، اور انسان-روبوٹ تعامل کی نزاکتوں کو حل کرتا ہے۔

#### 1.1.2. ہیومنوائڈ کنٹرول میں مضبوط سیکھنا

مضبوط سیکھنا (RL) ایک طاقتور فریم ورک ہے جہاں ایک ایجنٹ ماحول میں ایکسیشنز کرکے اور ایک تسلسل کے انعام سگنل کو زیادہ سے زیادہ کرکے فیصلے کرنا سیکھتا ہے۔ ہیومنوائڈ کنٹرول میں، RL روبوٹس کو پیچیدہ موٹر اسکلز، توازن، چلنے چلنا، اور مینیپولیشن کو سیکھنے کے قابل بناتا ہے۔ روبوٹ، ایک RL ایجنٹ کے طور پر، مختلف ایکشنز (جیسے جوائنٹ ٹورکس، کنیمیٹک کمانڈس) کو امتحان کرتا ہے اور ان کے نتائج کا مشاہدہ کرتا ہے، مطلوبہ رویوں (جیسے توازن برقرار رکھنا، ہدف تک پہنچنا) کے لیے مثبت انعامات اور ناپسندیدہ ایکشنز (جیسے گرنا، تصادم) کے لیے سزا کے طور پر۔ گہرائی مضبوط سیکھنا (DRL)، جو RL کو گہرے نیورل نیٹ ورکس کے ساتھ جوڑتا ہے، نے اس فیلڈ کو کافی حد تک آگے بڑھایا ہے، جس سے ہیومنوائڈز کو موومنٹ کے پرائمرز کو براہ راست پروگرام کیے بغیر، زیادہ سے زیادہ سینسر ڈیٹا (جیسے کیمرہ امیجز، پروپریوسیفیو فیڈ بیک) سے سیکھنے اور پیچیدہ کاموں کو ماسٹر کرنے کے قابل بناتا ہے۔

#### 1.1.3. نقل اور مظاہرے سے سیکھنا

نقل سیکھنا (IL)، جسے مظاہرے سے سیکھنا (LfD) کے نام سے بھی جانا جاتا ہے، روبوٹس کے لیے اسکلز حاصل کرنے کا ایک سمجھدار طریقہ فراہم کرتا ہے جو انسان یا ماہر مظاہروں کو دیکھ کر سیکھتے ہیں۔ کسی کام کے لیے انعام کے فنکشن یا پیچیدہ کنٹرول پالیسیز کو صفر سے ڈیزائن کرنے کے بجائے، روبوٹس سیدھے طور پر دیکھے گئے ٹریجکٹریز، ایکشنز، یا ویژوئل سگنلز سے سیکھتے ہیں۔ ہیومنوائڈ روبوٹس کے لیے، IL خاص طور پر ان کاموں کے لیے قیمتی ہے جن میں سماجی مطابقت، پیچیدہ مینیپولیشن ٹاسکس، یا انسانوں کے ساتھ مل کر کام کرنے کی نزاکتیں شامل ہیں۔ یہ تکنیکیں سلوک کے کلوننگ سے شروع ہوتی ہیں، جہاں ایک پالیسی براہ راست مشاہدہ کردہ ڈیٹا کی بنیاد پر اوبزرویشنز کو ایکشنز میں میپ کرتی ہے، اور مزید ترقی یافتہ طریقوں جیسے معکوس مضبوط سیکھنا (IRL) تک جاتی ہیں، جو ماہر کے رویے کو سمجھنے والے بنیادی انعام کے فنکشن کو استنباط کرتا ہے، جس سے روبوٹ کو سیکھے گئے اسکل کو جنرلائز اور آپٹیمائز کرنے کی اجازت ملتی ہے۔

#### 1.1.4. ٹرانسفر لرننگ اور میٹا لرننگ برائے روبوٹ اسکلز

ٹرانسفر لرننگ اور میٹا لرننگ روبوٹ سیکھنے میں ڈیٹا کی مؤثریت اور جنرلائزیشن کے چیلنج کو حل کرتے ہیں۔ ٹرانسفر لرننگ ایک کام یا ڈومین سے حاصل کردہ علم کو کسی دوسرے لیکن متعلقہ کام میں سیکھنے کو بہتر بنانے کے لیے استعمال کرتا ہے۔ مثال کے طور پر، ایک ہیومنوائڈ روبوٹ کسی شبیہ سازی ماحول میں سیکھے گئے چلنے کے اسکلز کو حقیقی دنیا کے منظر نامے میں منتقل کر سکتا ہے یا کسی نئی چیز کو تھامنے کی ایک پالیسی کو ایک نئی، نامعلوم چیز پر ایڈجسٹ کر سکتا ہے۔ میٹا لرننگ، یا "لرن ٹو لرن"، اس ایک قدم آگے بڑھاتا ہے جس میں روبوٹس کو کم سے کم نئے ڈیٹا کے ساتھ نئے کاموں یا ماحول میں فوراً ایڈجسٹ کرنے کے قابل بناتا ہے۔ یہ ہیومنوائڈز کے لیے انتہائی اہم ہے جنہیں متحرک، نئے منظر ناموں میں تیزی سے نئے اسکلز حاصل کرنے کی ضرورت ہوتی ہے، جس سے وہ زیادہ ورسٹائل اور مطابقت پذیر بنتے ہیں۔

### 1.2. اسکل کی نمائندگی اور جنرلائزیشن

#### 1.2.1. پیچیدہ موٹر اسکلز کی نمائندگی

پیچیدہ موٹر اسکلز کی مؤثر نمائندگی روبوٹ سیکھنے اور جنرلائزیشن کے لیے بنیادی ہے۔ سادہ پوائنٹ ٹو پوائنٹ موومنٹس کے برعکس، انسان نما اسکلز میں کئی ڈگریز آف فریڈم، باریک فورس کنٹرول، اور اڈاپٹو ٹائمِنگ کا پیچیدہ ا coordination شامل ہوتا ہے۔ روبوٹس کو اسپیسیو ٹیمپورل ڈائنا مکس کو کیپچر کرنے کے قابل ہونا چاہیے جبکہ یہ کمپیکٹ اور تشریح کے قابل رہے۔ عام طریقے میں ٹریجکٹری-بیسڈ نمائندگی (جیسے ڈائنا مک موومنٹ پرائمرز DMPs، گاؤسین مکسچر ماڈلز GMMs) شامل ہیں، جو موومنٹس کی شکل اور ٹائمِنگ کو انکوڈ کرتے ہیں؛ فورس/ٹورکو پروفائلز، جو کمپلائینٹ مینیپولیشن کے لیے اہم ہیں؛ اور گہرے لرننگ ماڈلز سے حاصل کردہ لیٹنٹ سپیس نمائندگیاں، جو ہائی ڈائمنشل سینسر موٹر ڈیٹا کو مطلب نما، کم ڈائمنشل فیچرز میں کمپریس کر سکتی ہیں جو اسکل کا جوہر کیپچر کرتے ہیں۔

#### 1.2.2. نئے منظر ناموں میں سیکھے گئے اسکلز کو جنرلائز کرنا

روبوٹ لرننگ میں ایک کلیدی چیلنج نئے منظر ناموں، اشیاء، یا ماحول میں سیکھے گئے اسکلز کو جنرلائز کرنے کی صلاحیت ہے جو تربیتی ڈیٹا سے مختلف ہوں۔ اس میں اشیاء کی پوزیشن، اورینٹیشن، سائز میں تبدیلیوں کے ساتھ ساتھ غیر متوقع رکاوٹوں کی موجودگی کے مطابقت پذیر ہونا شامل ہے۔ جنرلائزیشن اکثر سینسری ان پٹ سے مضبوط، ان ویرینٹ فیچرز سیکھنے پر انحصار کرتا ہے، جس میں سیمیولیشن میں ڈومین رینڈمائزیشن کا استعمال کرنا شامل ہے تاکہ روبوٹ کو مختلف حالات کا سامنا کرنا پڑے، اور میٹا لرننگ کا استعمال کرنا تاکہ نئے منظر ناموں میں فوراً ایڈجسٹ کیا جا سکے۔ ترکیبیں جیسے ہائیرارکیکل اسکل لرننگ، جہاں ہائی لیول کے منصوبے کو اڈاپٹیبل لو لیول پرائمرز کے ساتھ جوڑا جاتا ہے، بھی بہتر جنرلائزیشن میں حصہ ڈالتی ہیں کیونکہ یہ ٹاسک کے اہداف کو مخصوص انجام دہی کی تفصیلات سے الگ کر دیتی ہیں۔

#### 1.2.3. ٹاسک اگنواسٹک بمقابلہ ٹاسک سپیسیفک اسکل لرننگ

روبوٹ لرننگ کے نقطہ نظر کو عام طور پر ٹاسک اگنواسٹک اور ٹاسک سپیسیفک اسکل لرننگ میں الگ کیا جا سکتا ہے۔ ٹاسک سپیسیفک لرننگ ایک مخصوص اسکل کو ایک متعینہ مقصد کے لیے حاصل کرنے پر توجہ مرکوز کرتا ہے، جس میں اکثر اس مخصوص کام کے لیے اعلی کارکردگی حاصل ہوتی ہے۔ مثال کے طور پر، ایک روبوٹ کسی مخصوص قسم کی چیز کو ایک مقررہ مقام سے اٹھانے کے لیے سیکھ سکتا ہے۔ اس کے برعکس، ٹاسک اگنواسٹک لرننگ جنرلائز کر سکنے والے موٹر پرائمرز یا نمائندگیوں کو سیکھنے کا نشانہ لگاتا ہے جو کئی کاموں کو حل کرنے کے لیے دوبارہ استعمال اور مرکب کیا جا سکتا ہے۔ یہ نقطہ نظر اکثر لیٹنٹ سپیسز آف اسکلز کو سیکھنے، ذاتی حوصلہ افزائی، یا کیوریosity ڈرائیو ایکسپلوریشن کا استعمال کرتا ہے، جس سے روبوٹ بنیادی موومنٹس (جیسے پہنچنا، دھکیلنا، توازن) کا ایک ریپرتوائر تعمیر کر سکتا ہے جسے نئے چیلنجوں کو حل کرنے کے لیے فلیکسیبلی طور پر جوڑا جا سکتا ہے۔

### 1.3. انٹرایکٹو لرننگ اور ہیومن-ان-دی-لوب روبوٹکس

#### 1.3.1. انسانی فیڈ بیک اور تصحیح کے ذریعے سیکھنا

انٹرایکٹو لرننگ، جہاں انسان روبوٹ کے سیکھنے کے عمل میں فعال طور پر حصہ لیتے ہیں، ہیومنوائڈ روبوٹس کو تیار کرنے کے لیے انتہائی اہم ہے۔ یہ نقطہ نظر انسانی ذہانت کو روبوٹ کی تربیت کو ہدایت دینے، غلطیوں کو درست کرنے، اور مظاہرے فراہم کرنے کے لیے استعمال کرتا ہے، جس سے اسکل اکویژن کو کافی حد تک تیز کیا جا سکتا ہے اور خود کار تربیت کی ضرورت کو کم کیا جا سکتا ہے۔ انسانی فیڈ بیک مختلف اشکال میں ہو سکتا ہے: صریح (جیسے زبانی حکم، جوائسٹک کنٹرول، روبوٹ کی کارکردگی کی جائزہ رائے) یا ضمنی (جیسے فزیولوجیکل سگنلز، گیز ٹریکنگ، مظاہروں کا مشاہدہ کرنا)۔ انسانی فیڈ بیک سے مضبوط سیکھنا (RLHF) اور انٹرایکٹو نقل سیکھنا نمایاں طریقے ہیں جو روبوٹس کو انسانی ان پٹ کے جواب میں اپنی پالیسیز کو فروغ دینے کے قابل بناتے ہیں، جس سے زیادہ انسان مرکزی اور مطابقت رکھنے والے رویے حاصل ہوتے ہیں۔

#### 1.3.2. آن لائن اڈاپٹیشن اور مسلسل سیکھنا

متحرک، کھلے اختتامی ماحول میں کام کرنے والے ہیومنوائڈ روبوٹس کو حقیقت میں اڈاپٹ اور آن لائن سیکھنے کی صلاحیت کی ضرورت ہوتی ہے۔ آن لائن اڈاپٹیشن روبوٹ کو اس وقت اپنے رویوں اور ماڈلز کو اڈجسٹ کرنے کی اجازت دیتا ہے جب یہ نئے منظر ناموں کا سامنا کر رہا ہو، اپنے جسم میں تبدیلیوں (جیسے پہننے اور ٹوٹنا)، یا ماحول میں تبدیلیوں کو سنبھال رہا ہو۔ یہ طویل مدت تک کارکردگی اور مضبوطی کو برقرار رکھنے کے لیے انتہائی ضروری ہے۔ مسلسل سیکھنا، جو اکثر انکریمنٹل لرننگ یا لائف لونگ لرننگ آرکیٹیکچرز کے ذریعے معاونت یافتہ ہوتا ہے، روبوٹ کو اپنی آپریشنل زندگی کے دوران علم کو جمع کرنے کی اجازت دیتا ہے، اس طرح کہ سیکھنے کے پرانے اسکلز کو بھولنے سے بچا جا سکے اور روبوٹ کے پاس اسکلز اور علم کا ایک کھلتا ہوا ریپرتوائر ہو، جس سے یہ زیادہ خود مختار اور مزاحم بن جاتا ہے۔

#### 1.3.3. انسان ساتھیوں کے ساتھ مشترکہ سیکھنا

مشترکہ سیکھنا ان منظر ناموں پر توجہ مرکوز کرتا ہے جہاں ہیومنوائڈز اور انسان کامن اہداف کو حاصل کرنے کے لیے ساتھ ساتھ سیکھتے ہیں، جو ایک مطابقت پذیر تعلق کو فروغ دیتا ہے۔ ان ترتیبات میں، انسان اور روبوٹ دونوں سیکھنے کے عمل میں حصہ لیتے ہیں، علم کا اشتراک کرتے ہیں، ایکشنز کا مظاہرہ کرتے ہیں، اور ایک دوسرے کو فیڈ بیک فراہم کرتے ہیں۔ اس میں مشترکہ کنٹرول شامل ہو سکتا ہے، جہاں روبوٹ انسان کو کسی کام میں مدد فراہم کرتا ہے، یا مشترکہ اسکل اکویژن، جہاں روبوٹ کسی انسان کے ساتھ کام کرتے ہوئے ایک کام سیکھتا ہے۔ مقصد ایسے روبوٹس تیار کرنا ہے جو صرف ٹولز نہیں بلکہ ایسے ذہین ساتھی ہوں جو انسانی نیت کو سمجھ سکیں، انسانی ایکشنز کی پیشن گوئی کر سکیں، اور اس کے رویوں کو ایڈجسٹ کر سکیں تاکہ مختلف کاموں میں زیادہ موثر اور سہل تعاون کو فروغ دیا جا سکے۔

### 1.4. روبوٹ سیکھنے کے لیے گہری سیکھنے کی تعمیرات

#### 1.4.1. ادراک-ایکشن لوپس میں کنولوشنل اور ریکرینٹ نیورل نیٹ ورکس

گہری سیکھنے کی تعمیرات جدید روبوٹ سیکھنے کے دل میں ہیں، خاص طور پر ہائی ڈائمنشل سینسر ڈیٹا اور پیچیدہ کنٹرول پالیسیز کو ہینڈل کرنے کے لیے۔ کنولوشنل نیورل نیٹ ورکس (CNNs) روبوٹ ادراک کے لیے کیمرہ امیجز یا ڈیپتھ سینسرز سے اشیاء کی پہچان، پوز اسٹیمیشن، اور منظر سمجھنے جیسے کاموں میں وسیع پیمانے پر استعمال ہوتے ہیں۔ ریکرینٹ نیورل نیٹ ورکس (RNNs)، بشمول LSTMs اور GRUs، ترتیبی ڈیٹا کو پروسیس کرنے کے لیے انتہائی اہم ہیں، جیسے روبوٹ ٹریجکٹریز، ٹائم سیریز سینسر ریڈنگز، اور قدرتی زبان کے کمانڈس، جو روبوٹس کو ٹیمپورل انحصاریت کو سمجھنے اور ہموار، ٹائمڈ ایکشنز بنانے کے قابل بناتے ہیں۔ جب ادراک-ایکشن لوپس میں انٹیگریٹ کیا جاتا ہے، تو یہ نیٹ ورک ہیومنوائڈز کو براہ راست خام حسی ان پٹس کو موٹر کمانڈس میں میپ کرنے کی اجازت دیتے ہیں، اینڈ ٹو اینڈ لرننگ سسٹمز بناتے ہیں جو ویژوئل سروو، نیویگیشن، اور مینیپولیشن جیسے کاموں کے لیے ہیں۔

#### 1.4.2. اسکل جنریشن کے لیے جنریٹو ماڈلز

جنریٹو ماڈلز، جیسے ویریئیشنل آٹو اینکوڈرز (VAEs) اور جنریٹو ایڈورسیریل نیٹ ورکس (GANs)، روبوٹکس میں اسکل جنریشن کے لیے زیادہ سے زیادہ استعمال ہو رہے ہیں۔ یہ ماڈل کامیاب روبوٹ رویوں یا ماحولیاتی کنفیگریشنز کے لیے بنیادی تقسیم سیکھ سکتے ہیں اور پھر نئے، قابل قبول اسکلز یا نئے تربیتی ڈیٹا کو سنتھیسائز کر سکتے ہیں۔ مثال کے طور پر، ایک جنریٹو ماڈل کسی گریسنگ موومنٹس کے سیٹ سے سیکھ سکتا ہے اور پھر نئی اشیاء کو گریسنگ کرنے یا مختلف جم کی صورت حالوں میں اڈاپٹ کرنے کے لیے ان موومنٹس کے ویری ایشنز تیار کر سکتا ہے۔ وہ عجیب بات کا پتہ لگانے، مستقبل کی حالت کی پیشن گوئی، یا منصوبہ بندی کے لیے بھی استعمال ہو سکتے ہیں، جس سے ایک روبوٹ کے رویوں کے ریپرتوائر کو وسعت دینے اور پیچیدہ، غیر قابل پیش گوئی ماحول میں اس کی خود مختاری کو بہتر بنانے کے لیے ایک طاقتور طریقہ فراہم کرتا ہے۔

#### 1.4.3. روبوٹک کنٹرول میں اٹینشن میکنزمز اور ٹرانسفارمرز

اٹینشن میکنزمز، جو قدرتی زبان کی پروسیسنگ میں مقبول ہوئے، اور ٹرانسفارمر آرکیٹیکچر روبوٹک کنٹرول میں نمایاں طور پر داخل ہو رہے ہیں۔ اٹینشن ایک نیورل نیٹ ورک کو اس کے ان پٹ (جیسے منظر میں مخصوص اشیاء، اہم سینسر ریڈنگز، کمانڈ میں اہم حصے) کے سب سے متعلقہ حصوں پر منتخب طور پر فوکس کرنے کی اجازت دیتا ہے جب فیصلے کر رہا ہو۔ یہ منتخب فوکس مضبوطی اور تشریح کو بہتر بنا سکتا ہے۔ ٹرانسفارمرز، جو اٹینشن پر مبنی ہیں، خاص طور پر ترتیبی ڈیٹا میں طویل رینج انحصاریت کو ماڈل کرنے اور پیچیدہ ریلیشنل ریزننگ کو ہینڈل کرنے میں ماہر ہیں۔ روبوٹکس میں، ان کو متعدد ماڈل سینسر فیوژن، جامع منصوبہ بندی کی پالیسیز کو سیکھنے، اور پیچیدہ انسانی ہدایات کو سمجھنے کے کاموں میں لاگو کیا جا رہا ہے، جس سے ہیومنوائڈز کو مختلف معلومات کے ذرائع کو پروسیس کرنے اور انتہائی نازک اور ماحولیاتی بیدار رویوں کو انجام دینے کے قابل بنایا جا سکتا ہے۔

## 2. ہیومنوائڈ چلنے چلنا اور مینیپولیشن کے لیے اعلیٰ کنٹرول کی حکمت عمل

### 2.1. ڈائنا مک بائی پیڈل چلنے چلنا

ہیومنوائڈ چلنے چلنا، خاص طور پر ڈائنا مک بائی پیڈل چلنے چلنا، ایک بے ترتیب کھڑے کی ا inherent عدم استحکام کے باعث اور انسان نما مائع کے خواہش کے ساتھ کنٹرول چیلنجوں کو پیش کرتا ہے۔ اعلیٰ کنٹرول کی حکمت عملیں اسٹیٹک استحکام سے آگے بڑھتی ہیں تاکہ مستحکم اور اڈاپٹیبل چلنا، دوڑنا، اور پیچیدہ زمینوں کو نیویگیٹ کرنا ممکن ہو سکے۔

#### 2.1.1. صفر مومینٹ پوائنٹ (ZMP) اور سینٹروڈل ڈائنا مکس کنٹرول

صفر مومینٹ پوائنٹ (ZMP) بائی پیڈل چلنے چلنے میں ایک بنیادی تصور ہے، جو زمین کے اس نقطہ کی نمائندگی کرتا ہے جس کے بارے میں روبوٹ پر کام کرنے والے تمام زوروں کا کل مومینٹ صفر ہے۔ سپورٹ پولی گون (روبوٹ کے پاؤں کا محدب ہلکا جو زمین کے ساتھ رابطے میں ہے) کے اندر ZMP کو برقرار رکھنا اسٹیٹک اور ڈائنا مک استحکام کے لیے ایک ضروری شرط ہے۔ سینٹروڈل ڈائنا مکس، جو روبوٹ کے مرکز کے ماس (CoM) اور اس کے زاویہ ویمومنٹم پر توجہ مرکوز کرتا ہے، ہول بڈی موومنٹ کو سمجھنے اور کنٹرول کرنے کے لیے ایک زیادہ جامع فریم ورک فراہم کرتا ہے۔ کنٹرول کی حکمت عملیاں اکثر ZMP ٹریجکٹریز کو منصوبہ بند کرنے میں شامل ہوتی ہیں جن کو بعد میں جوائنٹ ٹورکس یا زور کو ٹریک کیا جاتا ہے، جس میں اکثر CoM ٹریجکٹری کی تعمیر کو متوازن اور مطلوبہ موومنٹ کو یقینی بنانے کے لیے جوڑا جاتا ہے۔

#### 2.1.2. چلنے اور دوڑنے کے لیے ماڈل پریڈکٹو کنٹرول (MPC)

ماڈل پریڈکٹو کنٹرول (MPC) ڈائنا مک بائی پیڈل چلنے چلنے کے لیے ایک طاقتور اوزار کے طور پر سامنے آیا ہے، جو مستقبل کے کنٹرول ان پٹس کو ایک محدود افق پر آپٹیمائز کرنے کی صلاحیت فراہم کرتا ہے جبکہ سسٹم ڈائنا مکس، رکاوٹوں (جیسے جوائنٹ لیمٹس، فریکشن کونز) اور مطلوبہ ٹریجکٹریز کو ذہن میں رکھتا ہے۔ چلنے اور دوڑنے کے لیے، MPC روبوٹ کی مستقبل کی حالت کی پیشن گوئی کر سکتا ہے اور متوازن برقرار رکھنے، مطلوبہ رفتار حاصل کرنے، اور رکاوٹوں کو نیویگیٹ کرنے کے لیے بہترین زور یا ٹورکس کا حساب کر سکتا ہے۔ یہ پیش گوئی کی صلاحیت مستقبل کے ایڈجسٹمنٹس کو فعال طور پر ممکن بناتی ہے تاکہ استحکام برقرار رکھا جا سکے، خاص طور پر بہت متحرک منظر ناموں میں، جسے جامع اور مضبوط چلنے چلنے کے لیے مناسب بنا دیتا ہے۔

#### 2.1.3. توازن اور رکاوٹ کو ختم کرنے کے لیے ہول بڈی کنٹرول

ہول بڈی کنٹرول (WBC) ایک ہیومنوائڈ روبوٹ کے کئی ڈگریز آف فریڈم کو پیچیدہ کاموں کو انجام دینے کے ساتھ ساتھ توازن برقرار رکھنے اور بیرونی رکاوٹوں کو ختم کرنے کے لیے مطابقت پذیر بنانے کے لیے انتہائی ضروری ہے۔ WBC فریم ورکس اکثر کنٹرول کو ایک آپٹیمائزیشن کے مسئلہ کے طور پر فارمولیٹ کرتے ہیں، جو کاموں (جیسے اینڈ ایفیکٹر ٹریکنگ، توازن، جوائنٹ لیمٹس) کو ترجیح دیتے ہیں اور جوائنٹ ٹورکس یا ایکسلریشنز کو پورے روبوٹ بڈی میں تقسیم کرتے ہیں۔ یہ نقطہ نظر روبوٹ کو اس کے ہاتھوں اور ٹورسو کو توازن کی بازیابی میں حصہ لینے، ضرب لینے کو سرکار کرنے، اور غیر متوقع دھکوں یا ناہموار زمین کا مقابلہ کرنے کے لیے استعمال کرنے کی اجازت دیتا ہے، جس سے مجموعی مضبوطی میں اضافہ ہوتا ہے۔

#### 2.1.4. کمپلائنس کنٹرول اور ویری ایبل امپیڈنس

کمپلائنس کنٹرول روبوٹ کو اس کے جوائنٹس یا اینڈ ایفیکٹرز پر ایک مطلوبہ امپیڈنس (سٹفنس اور ڈیمپنگ) کو ظاہر کرنے کی اجازت دیتا ہے، جس سے یہ ماحول کے ساتھ محفوظ اور مضبوط طریقے سے بات چیت کر سکے۔ ویری ایبل امپیڈنس کنٹرول اس ایک قدم آگے بڑھاتا ہے، جو روبوٹ کو مسئلے یا ماحولیاتی حالات کی بنیاد پر اس کی کمپلائنس کو ڈائنامک طور پر ایڈجسٹ کرنے کی اجازت دیتا ہے۔ مثال کے طور پر، ایک روبوٹ درست مینیپولیشن کے دوران اعلی سٹفنس کا مظاہرہ کر سکتا ہے لیکن ضرب کھانے یا مطابقت پذیر چلنے چلنے کے دوران کم سٹفنس کا مظاہرہ کر سکتا ہے۔ یہ اڈاپٹیبلیٹی ابھاروں، غیر متوقع رابطوں، اور قدرتی، مائع موومنٹس حاصل کرنے کے لیے انتہائی ضروری ہے۔

### 2.2. ڈیکسٹر س مینیپولیشن اور گریسنگ

ڈیکسٹر س مینیپولیشن اور گریسنگ انسانوں کے ماحول میں اشیاء کے ساتھ بات چیت کرنے اور پیچیدہ کاموں کو انجام دینے کے لیے اہم ہیں۔ یہ صلاحیتیں متعدد آرٹیکولیٹڈ ہاتھوں اور بازوں پر درست کنٹرول کی ضرورت رکھتی ہیں، جس میں اکثر پیچیدہ کنٹیکٹ ڈائنا مکس شامل ہوتے ہیں۔

#### 2.2.1. ملٹی کنٹیکٹ مینیپولیشن کی حکمت عمل

روایتی مینیپولیشن اکثر اینڈ ایفیکٹر اور اشیاء کے درمیان ایک سنگل پوائنٹ آف کنٹیکٹ کا فرض کرتا ہے۔ ملٹی کنٹیکٹ مینیپولیشن اس کو منظر ناموں تک بڑھاتا ہے جہاں متعدد پوائنٹس آف کنٹیکٹ، ممکنہ طور پر ہتھیلی، انگلیوں، اور ہاتھ کے بازو کے ساتھ، اشیاء کو تھامنے اور مینیپولیٹ کرنے کے لیے استعمال ہوتے ہیں۔ حکمت عملیاں کنٹیکٹ زور، فریکشن رکاوٹوں، اور اشیاء کے استحکام کو بہتر بنانے میں شامل ہوتی ہیں۔ یہ نقطہ نظر گریپس کی مضبوطی میں اضافہ کرتا ہے، بھاری یا غیر معمولی شکل والی اشیاء کو مینیپولیٹ کرنے کے قابل بناتا ہے، اور ہینڈ میں مینیپولیشن کی صلاحیتوں کو ممکن بناتا ہے۔

#### 2.2.2. ہاتھوں اور بازوؤں کے ہم آہنگ کنٹرول

ہیومنوائڈ روبوٹس کے ان ہاتھوں اور بازوؤں میں کئی ڈگریز آف فریڈم ہوتے ہیں، جس سے مطابقت پذیر کنٹرول ایک بڑا چیلنج بن جاتا ہے۔ ہم آہنگ کنٹرول نقطہ نظر میں انسانی ہاتھ اور بازو کی حرکات میں قدرتی تعلقات یا "سمنجیز" کو شناخت کرنا اور ان کا استعمال کرنا شامل ہے۔ ایک کم ڈائمنشل سیٹ آف سمنجیک پیرامیٹرز کو کنٹرول کر کے، روبوٹ پیچیدہ مینیپولیشن ٹاسکس کو کم کمپیوٹیشنل بوجھ اور زیادہ سمجھدار کنٹرول کے ساتھ حاصل کر سکتا ہے، جس سے زیادہ انسان نما اور کارآمد گریسنگ اور اشیاء کے ساتھ بات چیت ممکن ہو جاتی ہے۔

#### 2.2.3. مطابقت پذیر بات چیت کے لیے فورس/ٹورک کنٹرول

فورس/ٹورک کنٹرول ڈیکسٹر س مینیپولیشن کے لیے انتہائی ضروری ہے، جو روبوٹ کو اشیاء یا ماحول پر لگائے گئے زور اور ٹورکس کو ریگولیٹ کرنے کی اجازت دیتا ہے۔ یہ خاص طور پر ان کاموں کے لیے اہم ہے جن میں مطابقت پذیر بات چیت کی ضرورت ہوتی ہے، جیسے کسی چیز کو سوراخ میں ڈالنا، کسی سطح کو چمکانا، یا نازک اشیاء کو ہینڈل کرنا۔ رابطہ کے زور کو سینسنگ کر کے اور جوائنٹ ٹورکس کو مطابق بناتے ہوئے، روبوٹ ان کاموں کو انجام دے سکتا ہے جن میں حساسیت اور اڈاپٹیبلیٹی کی ضرورت ہوتی ہے، اشیاء یا روبوٹ کو نقصان پہنچنے سے بچا سکتا ہے، اور باریک تر مینیپولیشن ممکن بناتا ہے۔

### 2.3. ٹریجکٹری آپٹیمائزیشن اور موومنٹ پلاننگ

ٹریجکٹری آپٹیمائزیشن اور موومنٹ پلاننگ ہیومنوائڈ روبوٹس کے لیے ڈائنامک، کالیژن فری، اور کنیمیٹکلی ممکن موومنٹس تیار کرنے کے لیے بنیاد ہیں، جو اکثر مخصوص کاموں اور ماحول کے لیے ہوتے ہیں۔

#### 2.3.1. آپٹیمائزیشن بیسڈ موومنٹ جنریشن

آپٹیمائزیشن بیسڈ موومنٹ جنریشن روبوٹ ٹریجکٹری تلاش کرنے کے مسئلے کو ایک آپٹیمائزیشن کے مسئلے کے طور پر فارمولیٹ کرتا ہے، جہاں ایک اہداف کا فنکشن (جیسے توانائی کی کھپت، وقت، جرک کو کم کرنا یا کام کی کامیابی کو زیادہ سے زیادہ کرنا) کو کنیمیٹک، ڈائنا مک، اور ماحولیاتی رکاوٹوں کے موضوع میں کم کیا جاتا ہے۔ یہ نقطہ نظر کمپلیکس ٹاسکس کے لیے انتہائی موثر اور قدرتی نظر آنے والے موومنٹس تیار کر سکتا ہے، جو توازن، جوائنٹ لیمٹس، اور کالیژن سے گریز کرنے جیسے عوامل کو ذہن میں رکھتا ہے۔

#### 2.3.2. حقیقت میں ری ایکٹیو موومنٹ پلاننگ

جبکہ آف لائن ٹریجکٹری آپٹیمائزیشن بہترین راستے تلاش کرنے کے لیے کام کر سکتی ہے، حقیقت میں ری ایکٹیو موومنٹ پلاننگ متحرک اور غیر یقینی ماحول میں کام کرنے کے لیے انتہائی ضروری ہے۔ اس میں غیر متوقع واقعات، متحرک رکاوٹوں، یا ماحول میں تبدیلیوں کے جواب میں تیزی سے ٹریجکٹریز تیار کرنا یا ان میں ترمیم کرنا شامل ہے۔ تکنیک جیسے ریپڈلی ایکسپلورنگ رینڈم ٹریز (RRT) ویرینٹس، پوٹینشل فیلڈز، یا سیمپلنگ بیسڈ میتھڈز کو حقیقت میں کارکردگی کے لیے اکثر ایڈجسٹ کیا جاتا ہے، جو ہیومنوائڈز کو خطرناک اور مؤثر طریقے سے چلنے اور بات چیت کرنے کی اجازت دیتا ہے۔

#### 2.3.3. انسان نما موومنٹ جنریشن

انسان نما موومنٹس کی تعمیر ایک کلیدی مقصد ہے جو قدرتی اور سماجی طور پر قابل قبول ہیومنوائڈ روبوٹس تیار کرنے کے لیے ہے۔ اس میں انسانی موٹر کنٹرول، بائومیکنکس، اور ادراک کے اصولوں کو موومنٹ پلاننگ اور کنٹرول الگورتھم میں شامل کرنا شامل ہے۔ تکنیک جیسے مظاہرے سے سیکھنا (LfD)، انسانی قیمت فنکشنز کو انورس آپٹیمل کنٹرول سے حاصل کرنا، اور انسانی موومنٹ ویریبیلٹی کے ماڈلز کو شامل کرنا انسان نما اور زیادہ سمجھنے والے روبوٹ موومنٹس کی طرف لے جا سکتا ہے جو انسانوں کے لیے سمجھنے اور بات چیت کرنے میں آسان ہوں گے۔

### 2.4. ہائبرڈ کنٹرول آرکیٹیکچرز

ہائبرڈ کنٹرول آرکیٹیکچرز مختلف کنٹرول پیراڈائمز کو جوڑتے ہیں تاکہ ان کی متعلقہ طاقت کو فائدہ دیا جا سکے، زیادہ مضبوط، لچکدار، اور قابل رہنے والے ہیومنوائڈ سسٹمز تیار کیے جا سکیں۔ یہ اکثر ماڈل بیسڈ کنٹرول کو ڈیٹا ڈرائیو لرننگ ایپروچز یا ہائیرارکیکل کنٹرول سسٹمز کے ساتھ انٹیگریٹ کرنا شامل کرتا ہے۔

#### 2.4.1. ماڈل بیسڈ اور لرننگ بیسڈ کنٹرول کو جوڑنا

ماڈل بیسڈ کنٹرول روبوٹ اور اس کے ماحول کے ریاضیاتی ماڈل پر انحصار کرتا ہے، جو استحکام کے ضمانتیں اور قابل پیش گوئی رویے کی پیش کش کرتا ہے۔ لرننگ بیسڈ کنٹرول، جیسے مضبوط سیکھنا یا نقل سیکھنا، روبوٹس کو ڈیٹا یا تجربے سے پیچیدہ رویوں کو حاصل کرنے کی اجازت دیتا ہے، نامعلوم ڈائنا مکس اور ماحول کے ساتھ مطابقت پذیر ہونے کے قابل بناتا ہے۔ ہائبرڈ ایپروچز ان کو جوڑتے ہیں، جہاں ماڈل بیسڈ کنٹرولر بنیادی استحکام اور جانے والے ڈائنا مکس کے لیے استعمال ہوتے ہیں، جبکہ لرننگ بیسڈ کمپوننٹس موومنٹس کو بہتر بناتے ہیں، ابھاروں کے ساتھ مطابقت پذیر ہوتے ہیں، یا نئے اسکلز حاصل کرتے ہیں، جس سے زیادہ مضبوط اور اڈاپٹیبل کارکردگی حاصل ہوتی ہے۔

#### 2.4.2. کمپلیکس ٹاسکس کے لیے ہائیرارکیکل کنٹرول سسٹمز

کمپلیکس ہیومنوائڈ ٹاسکس اکثر ہائیرارکیکل کنٹرول آرکیٹیکچرز سے فائدہ اٹھاتے ہیں، جہاں ہائی لیول کے کنٹرولرز مطلق اہداف یا رویوں کو بیان کرتے ہیں (جیسے "گول تک چلنا، "چیز اٹھانا)، اور لو لیول کے کنٹرولرز ان کو مخصوص جوائنٹ کمانڈس یا ٹورکس میں تبدیل کرتے ہیں۔ یہ ماڈولریٹی سسٹم کی ڈیزائن کو آسان بناتی ہے، خرابی کی بازیابی کو فروغ دیتی ہے، اور مؤثر ٹاسک ڈیکمپوزیشن کی اجازت دیتی ہے۔ ہائیرارکی کے مختلف لیول مختلف فریکوئنسیز اور انتزاع کے لیولز پر کام کر سکتے ہیں، جو مجموعی اہداف کو حاصل کرنے کے لیے مطابقت پذیر ہوتے ہیں جبکہ روبوٹ کے کئی ڈگریز آف فریڈم کا انتظام کرتے ہیں۔

#### 2.4.3. نامعلوم ماحول کے لیے اڈاپٹیو کنٹرول

ہیومنوائڈ روبوٹس اکثر ماحول میں نامعلوم یا تبدیل ہوتے ہوئے خصوصیات کا سامنا کرتے ہیں، جیسے مختلف زمین کی فریکشن، نامعلوم اشیاء کے ماسز، یا غیر متوقع رکاوٹیں۔ اڈاپٹیو کنٹرول کی حکمت عملیاں روبوٹ کے کنٹرولر پیرامیٹرز کو حقیقت میں فیڈ بیک کی بنیاد پر آن لائن ایڈجسٹ کرنے کی اجازت دیتی ہیں، جو روبوٹ کو ان ابھاروں کے باوجود کارکردگی برقرار رکھنے کے قابل بناتی ہے۔ اس میں ماحولیاتی پیرامیٹرز کا اندازہ لگانا، امپیڈنس لیولز ایڈجسٹ کرنا، یا کنٹرول گینز کو تبدیل کرنا شامل ہو سکتا ہے تاکہ مختلف غیر یقینی حالات میں مستحکم اور مؤثر کارکردگی یقینی بنائی جا سکے۔

## 3. انسان-روبوٹ بات چیت اور تعاون

### 3.1. انسان-روبوٹ تعاون (HRC) کے اصول

#### 3.1.1. مشترکہ کام کے علاقوں میں حفاظت

#### 3.1.2. باہمی سمجھ اور نیت کی پہچان

#### 3.1.3. ٹاسک کی تقسیم اور کردار کی تفویض

### 3.2. سمجھدار بات چیت کے ذرائع

#### 3.2.1. تقریر اور قدرتی زبان کے انٹرفیسز

#### 3.2.2. اشاروں کی پہچان اور جسمانی ہیپٹک بات چیت

#### 3.2.3. ایفیکٹو کمپیوٹنگ اور جذبات کی پہچان

#### 3.2.4. اضافی حقیقت اور پہننے والے انٹرفیسز

### 3.3. ایچ آر آئی کے سماجی اور نفسیاتی پہلو

#### 3.3.1. اعتماد، قبولیت، اور صارف کا تجربہ

#### 3.3.2. انسان نما کرنا اور روبوٹ ڈیزائن

#### 3.3.3. سماجی روبوٹکس کے لیے اخلاقی ہدایات

### 3.4. انسان-روبوٹ بات چیت سے سیکھنا

#### 3.4.1. صارف کی ترجیحات اور عادات سیکھنا

#### 3.4.2. انٹرایکٹو فیڈ بیک کے ذریعے رویے کو ایڈجسٹ کرنا

#### 3.4.3. ایچ آر آئی میں کو-لرننگ اور اسکل ٹرانسفر

## 4. متحرک ماحول میں منظر کی سمجھ اور منظر سمجھنا

### 4.1. ہیومنوائڈز کے لیے اعلیٰ سینسری سسٹمز

#### 4.1.1. ملٹی ماڈل سینسر فیوژن (وژن، لائیڈر، ہیپٹکس، پروپریوسیفیکشن)

#### 4.1.2. ہائی ریزولوشن وژن اور ڈیپتھ سینسنگ

#### 4.1.3. ٹیکٹائل سینسنگ اور فورس-ٹورک سینسرز

### 4.2. حقیقت میں اشیاء کی پہچان اور ٹریکنگ

#### 4.2.1. اشیاء کی پہچان اور سیگمینٹیشن کے لیے گہری سیکھنے

#### 4.2.2. متحرک اشیاء اور ڈیفورم ایبل اشیاء کو ٹریک کرنا

#### 4.2.3. پوز اسٹیمیشن اور 3D ریکنstrukشن

### 4.3. سیمینٹک منظر سمجھنا

#### 4.3.1. منظر گراف جنریشن اور سپیشل ریزننگ

#### 4.3.2. سرگرمی کی پہچان اور انسانی پوز اسٹیمیشن

#### 4.3.3. ماحولیاتی ڈائنا مکس کی پیشن گوئی کا ماڈل

### 4.4. نیویگیشن اور ماحول کی میپنگ

#### 4.4.1. متحرک ماحول میں ایک ساتھ مقام کی درستی اور میپنگ (SLAM)

#### 4.4.2. حقیقت میں راستہ منصوبہ بندی اور رکاوٹ سے بچنا

#### 4.4.3. انسان آگاہ نیویگیشن

## 5. ایمبوڈیڈ انٹیلی جنس اور ٹاسک-اورینٹڈ اے آئی

### 5.1. کوگنیشن اور ایکشن کا انٹیگریشن

#### 5.1.1. ادراک، منصوبہ بندی، اور انجام دہی کو پل باندھنا

#### 5.1.2. ہیومنوائڈز کے لیے ٹاسک منصوبہ بندی اور ڈیکمپوزیشن

#### 5.1.3. ہدف کے مطابق رویہ اور استدلال

### 5.2. دنیا کی ماڈلنگ اور علم کی نمائندگی

#### 5.2.1. علامتی اور سب-سمبولک علم کا انٹیگریشن

#### 5.2.2. جسمانی تعاملات کے لیے عام سینس ریزننگ

#### 5.2.3. تجربے سے دنیا کے ماڈلز سیکھنا

### 5.3. ملٹی ٹاسک لرننگ اور جنرلائزیشن

#### 5.3.1. ٹاسکس کے درمیان شیئر کردہ نمائندگیاں سیکھنا

#### 5.3.2. کم ڈیٹا کے ساتھ نئے ٹاسکس کے لیے اڈاپٹ کرنا

#### 5.3.3. جاری لرننگ اور کیٹاسٹرو فورگٹنگ

### 5.4. ایمبوڈیڈ اے آئی کے لیے آرکیٹیکچرز

#### 5.4.1. ایمبوڈیڈ ایجنٹس کے لیے اینڈ ٹو اینڈ لرننگ

#### 5.4.2. ماڈولر اور ہائبرڈ اے آئی آرکیٹیکچرز

#### 5.4.3. بڑے زبان کے ماڈلز (LLMs) اور وژن-زبان کے ماڈلز (VLMs) روبوٹکس میں

## 6. ہیومنوائڈ اے آئی کے اخلاقی اعتبارات اور معاشرتی اثرات

### 6.1. ہیومنوائڈ روبوٹکس کے لیے اخلاقی فریم ورکس

#### 6.1.1. ذمہ دار اے آئی اور روبوٹکس کے اصول

#### 6.1.2. ویلیو الائمنٹ اور اخلاقی فیصلہ سازی

#### 6.1.3. خود مختار سسٹمز میں ذمہ داری اور ذمہ داری

### 6.2. حفاظت، رازداری، اور سیکیورٹی

#### 6.2.1. انسان-روبوٹ کا اشتراک کرنے والے ماحول میں جسمانی حفاظت

#### 6.2.2. ڈیٹا کی رازداری اور نگرانی کے مسائل

#### 6.2.3. روبوٹک سسٹمز کے لیے سائبر سیکیورٹی

### 6.3. معاشرتی-معاشی اثرات

#### 6.3.1. روزگار اور کارکردگی کی تبدیلی

#### 6.3.2. معاشی عدم مساوات اور ٹیکنالوجی تک رسائی

#### 6.3.3. ہیومنوائڈ روبوٹس کے ساتھ کام کے مستقبل

### 6.4. ریگولیٹری اور پالیسی کے چیلنج

#### 6.4.1. ہیومنوائڈ اے آئی کے لیے قانونی فریم ورکس تیار کرنا

#### 6.4.2. بین الاقوامی تعاون اور معیارات

#### 6.4.3. ہیومنوائڈ روبوٹکس کے بارے میں عوامی تاثر اور قبولیت

## 2. ہیومنوائڈ چلنے چلنا اور مینیپولیشن کے لیے اعلیٰ کنٹرول کی حکمت عمل

### 2.1. ڈائنا مک بائی پیڈل چلنے چلنا

ہیومنوائڈ چلنے چلنا، خاص طور پر ڈائنا مک بائی پیڈل چلنے چلنا، چلنے چلنے کے ا inherent عدم استحکام کے باعث اور انسان نما مائع کے خواہش کے ساتھ کنٹرول چیلنجوں کو پیش کرتا ہے۔ اعلیٰ کنٹرول کی حکمت عملیں اسٹیٹک استحکام سے آگے بڑھتی ہیں تاکہ مستحکم اور اڈاپٹیبل چلنا، دوڑنا، اور پیچیدہ زمینوں کو نیویگیٹ کرنا ممکن ہو سکے۔

#### 2.1.1. صفر مومینٹ پوائنٹ (ZMP) اور سینٹروڈل ڈائنا مکس کنٹرول

صفر مومینٹ پوائنٹ (ZMP) بائی پیڈل چلنے چلنے میں ایک بنیادی تصور ہے، جو زمین کے اس نقطہ کی نمائندگی کرتا ہے جس کے بارے میں روبوٹ پر کام کرنے والے تمام زوروں کا کل مومینٹ صفر ہے۔ سپورٹ پولی گون (روبوٹ کے پاؤں کا محدب ہلکا جو زمین کے ساتھ رابطے میں ہے) کے اندر ZMP کو برقرار رکھنا اسٹیٹک اور ڈائنا مک استحکام کے لیے ایک ضروری شرط ہے۔ سینٹروڈل ڈائنا مکس، جو روبوٹ کے مرکز کے ماس (CoM) اور اس کے زاویہ ویمومنٹم پر توجہ مرکوز کرتا ہے، ہول بڈی موومنٹ کو سمجھنے اور کنٹرول کرنے کے لیے ایک زیادہ جامع فریم ورک فراہم کرتا ہے۔ کنٹرول کی حکمت عملیاں اکثر ZMP ٹریجکٹریز کو منصوبہ بند کرنے میں شامل ہوتی ہیں جن کو بعد میں جوائنٹ ٹورکس یا زور کو ٹریک کیا جاتا ہے، اکثر CoM ٹریجکٹری کی تعمیر کے ساتھ جوڑا جاتا ہے تاکہ توازن اور مطلوبہ موومنٹ کو یقینی بنایا جا سکے۔

#### 2.1.2. چلنے اور دوڑنے کے لیے ماڈل پریڈکٹو کنٹرول (MPC)

ماڈل پریڈکٹو کنٹرول (MPC) ڈائنا مک بائی پیڈل چلنے چلنے کے لیے ایک طاقتور اوزار کے طور پر سامنے آیا ہے، جو مستقبل کے کنٹرول ان پٹس کو ایک محدود افق پر آپٹیمائز کرنے کی صلاحیت فراہم کرتا ہے جبکہ سسٹم ڈائنا مکس، رکاوٹوں (جیسے جوائنٹ لیمٹس، فریکشن کونز) اور مطلوبہ ٹریجکٹریز کو ذہن میں رکھتا ہے۔ چلنے اور دوڑنے کے لیے، MPC روبوٹ کی مستقبل کی حالت کی پیشن گوئی کر سکتا ہے اور متوازن برقرار رکھنے، مطلوبہ رفتار حاصل کرنے، اور رکاوٹوں کو نیویگیٹ کرنے کے لیے بہترین زور یا ٹورکس کا حساب کر سکتا ہے۔ یہ پیش گوئی کی صلاحیت مستقبل کے ایڈجسٹمنٹس کو فعال طور پر ممکن بناتی ہے تاکہ استحکام برقرار رکھا جا سکے، خاص طور پر بہت متحرک منظر ناموں میں، جسے جامع اور مضبوط چلنے چلنے کے لیے مناسب بنا دیتا ہے۔

#### 2.1.3. توازن اور رکاوٹ کو ختم کرنے کے لیے ہول بڈی کنٹرول

ہول بڈی کنٹرول (WBC) ایک ہیومنوائڈ روبوٹ کے کئی ڈگریز آف فریڈم کو پیچیدہ کاموں کو انجام دینے کے ساتھ ساتھ توازن برقرار رکھنے اور بیرونی رکاوٹوں کو ختم کرنے کے لیے مطابقت پذیر بنانے کے لیے انتہائی ضروری ہے۔ WBC فریم ورکس اکثر کنٹرول کو ایک آپٹیمائزیشن کے مسئلہ کے طور پر فارمولیٹ کرتے ہیں، جو کاموں (جیسے اینڈ ایفیکٹر ٹریکنگ، توازن، جوائنٹ لیمٹس) کو ترجیح دیتے ہیں اور جوائنٹ ٹورکس یا ایکسلریشنز کو پورے روبوٹ بڈی میں تقسیم کرتے ہیں۔ یہ نقطہ نظر روبوٹ کو اس کے ہاتھوں اور ٹورسو کو توازن کی بازیابی میں حصہ لینے، ضرب لینے کو سرکار کرنے، اور غیر متوقع دھکوں یا ناہموار زمین کا مقابلہ کرنے کے لیے استعمال کرنے کی اجازت دیتا ہے، جس سے مجموعی مضبوطی میں اضافہ ہوتا ہے۔

#### 2.1.4. کمپلائنس کنٹرول اور ویری ایبل امپیڈنس

کمپلائنس کنٹرول روبوٹ کو اس کے جوائنٹس یا اینڈ ایفیکٹرز پر ایک مطلوبہ امپیڈنس (سٹفنس اور ڈیمپنگ) کو ظاہر کرنے کی اجازت دیتا ہے، جس سے یہ ماحول کے ساتھ محفظ اور مضبوط طریقے سے بات چیت کر سکے۔ ویری ایبل امپیڈنس کنٹرول اس ایک قدم آگے بڑھاتا ہے، جو روبوٹ کو مسئلے یا ماحولیاتی حالات کی بنیاد پر اس کی کمپلائنس کو ڈائنامک طور پر ایڈجسٹ کرنے کی اجازت دیتا ہے۔ مثال کے طور پر، ایک روبوٹ درست مینیپولیشن کے دوران اعلی سٹفنس کا مظاہرہ کر سکتا ہے لیکن ضرب کھانے یا مطابقت پذیر چلنے چلنے کے دوران کم سٹفنس کا مظاہرہ کر سکتا ہے۔ یہ اڈاپٹیبلیٹی ابھاروں، غیر متوقع رابطوں، اور قدرتی، مائع موومنٹس حاصل کرنے کے لیے انتہائی ضروری ہے۔